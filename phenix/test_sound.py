import queue
import sounddevice as sd
import numpy as np
from faster_whisper import WhisperModel
from fuzzywuzzy import fuzz

# --- –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ ---
# tiny - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —à–≤–∏–¥–∫–æ, small - —Ç–æ—á–Ω—ñ—à–µ, –∞–ª–µ —Ç—Ä–æ—Ö–∏ –ø–æ–≤—ñ–ª—å–Ω—ñ—à–µ
model = WhisperModel("tiny", device="cpu", compute_type="int8")

# --- –ß–µ—Ä–≥–∞ –¥–ª—è –∞—É–¥—ñ–æ ---
audio_queue = queue.Queue()
samplerate = 16000
blocksize = 512  # –º–∞–ª–µ–Ω—å–∫—ñ –±–ª–æ–∫–∏ –¥–ª—è –º—ñ–Ω—ñ–º–∞–ª—å–Ω–æ—ó –∑–∞—Ç—Ä–∏–º–∫–∏

# --- –°–ø–∏—Å–æ–∫ –∫–ª—é—á–æ–≤–∏—Ö –∫–æ–º–∞–Ω–¥ ---
commands = ["–≤—ñ–¥–∫—Ä–∏–π –±—Ä–∞—É–∑–µ—Ä", "–∑–∞–ø—É—Å—Ç–∏ –º—É–∑–∏–∫—É", "—Å–∫–∞–∂–∏ —á–∞—Å", "–ø–æ—à—É–∫ –≤ Google"]

# --- –§—É–Ω–∫—Ü—ñ—è –∫–æ–ª–±–µ–∫ –¥–ª—è –º—ñ–∫—Ä–æ—Ñ–æ–Ω–∞ ---
def audio_callback(indata, frames, time, status):
    if status:
        print("‚ö†Ô∏è", status)
    audio_queue.put(indata.copy())

# --- –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –ø–æ—à—É–∫—É –Ω–∞–π–±–ª–∏–∂—á–æ—ó –∫–æ–º–∞–Ω–¥–∏ ---
def match_command(text):
    text = text.lower()
    best_score = 0
    best_cmd = None
    for cmd in commands:
        score = fuzz.ratio(text, cmd)
        if score > best_score:
            best_score = score
            best_cmd = cmd
    if best_score > 60:  # –ø–æ—Ä—ñ–≥ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç—ñ
        return best_cmd
    return None

# --- –û—Å–Ω–æ–≤–Ω–∏–π —Ü–∏–∫–ª ---
with sd.InputStream(samplerate=samplerate, channels=1, blocksize=blocksize, callback=audio_callback):
    print("üé§ –ì–æ–≤–æ—Ä—ñ—Ç—å –∫–æ–º–∞–Ω–¥—É... (Ctrl+C —â–æ–± –∑—É–ø–∏–Ω–∏—Ç–∏)")
    audio_buffer = np.zeros(0, dtype=np.float32)

    try:
        while True:
            while not audio_queue.empty():
                chunk = audio_queue.get()
                audio_buffer = np.concatenate((audio_buffer, chunk[:, 0]))

            # –Ø–∫—â–æ –Ω–∞–∫–æ–ø–∏—á–∏–ª–æ—Å—è 0.5 —Å–µ–∫—É–Ω–¥–∏ –∞—É–¥—ñ–æ ‚Üí –æ–±—Ä–æ–±–ª—è—î–º–æ
            if len(audio_buffer) > samplerate * 0.5:
                # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
                audio_input = audio_buffer / np.max(np.abs(audio_buffer))

                # –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è
                segments, info = model.transcribe(audio_input, language="uk")
                text = " ".join([seg.text for seg in segments]).strip()
                if text:
                    cmd = match_command(text)
                    if cmd:
                        print(f"üó£Ô∏è –†–æ–∑–ø—ñ–∑–Ω–∞–Ω–∞ –∫–æ–º–∞–Ω–¥–∞: {cmd}")
                    else:
                        print(f"üó£Ô∏è –í–∏ —Å–∫–∞–∑–∞–ª–∏: {text}")

                # –û—á–∏—â—É—î–º–æ –±—É—Ñ–µ—Ä
                audio_buffer = np.zeros(0, dtype=np.float32)

    except KeyboardInterrupt:
        print("\n–ó–∞–≤–µ—Ä—à–µ–Ω–æ.")
